{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7QpYErFfmyZ"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import *\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "pd.options.display.max_colwidth = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3l1Zahrfwe9",
        "outputId": "708b30f8-7f58-420e-e629-5da43420a345"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Give me the input path\n",
            "nasdaq_input.csv\n",
            "Give encoder name\n",
            "encoder_C.h5\n",
            "Number of rows and columns: (3651, 100)\n",
            "[[0.04579599]\n",
            " [0.03457418]\n",
            " [0.04052691]\n",
            " [0.03835925]\n",
            " [0.0418942 ]\n",
            " [0.0429947 ]\n",
            " [0.05301597]\n",
            " [0.05861853]\n",
            " [0.05850181]\n",
            " [0.06403768]]\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "365\n",
            "    0        1        2        3     ...     1092     1093     1094     1095\n",
            "0      a  20.0751  20.5983  28.6123  ...   200.45  152.221  149.331  203.463\n",
            "1     aa  84.8842  87.1009   125.64  ...  122.889  87.9198  86.9462  115.004\n",
            "2   aaba     24.7  26.4754  36.6751  ...   166.63  139.835  146.086   211.86\n",
            "3   aapl  21.8878  21.9443  31.3208  ...  428.019  350.145  356.896  579.277\n",
            "4    abc  27.3991  27.1462  35.6427  ...  188.178  132.514  129.275  177.702\n",
            "..   ...      ...      ...      ...  ...      ...      ...      ...      ...\n",
            "95   cvs  23.2942  23.5781  29.0963  ...  174.409  119.685  119.069  165.257\n",
            "96   cvx   37.547  38.6107  46.4965  ...  315.433   209.56  209.778  308.415\n",
            "97     d  33.7286  35.1899  40.9598  ...  211.323  167.971   157.95  218.597\n",
            "98   dal  4124.98  3897.62  5817.67  ...  588.974  407.505  407.395  583.031\n",
            "99   dds  39.4229  38.2799  54.6006  ...  161.615   109.81  110.262  163.386\n",
            "\n",
            "[100 rows x 1096 columns]\n",
            "Give me the query path\n",
            "nasdaq_query.csv\n",
            "Number of rows and columns: (3651, 10)\n",
            "[[0.04586814]\n",
            " [0.04420205]\n",
            " [0.04441462]\n",
            " [0.04430546]\n",
            " [0.04441462]\n",
            " [0.04527065]\n",
            " [0.04674141]\n",
            " [0.04575898]\n",
            " [0.04652309]\n",
            " [0.04760318]]\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "365\n",
            "   0        1        2        3     ...     1092     1093     1094     1095\n",
            "0     x  42.6659  42.4589  59.1539  ...  96.0055  66.9015  68.5787  94.3951\n",
            "1   xel  16.1382  17.1973  20.5963  ...  130.989  97.9871   94.146  140.677\n",
            "2    xl  141.571  137.237  221.797  ...   110.08  77.5834  75.9146  106.838\n",
            "3  xlnx  41.2303  41.1185  59.2992  ...  189.212  153.652  149.402   205.61\n",
            "4   xom  36.2533   37.724  42.2803  ...   171.21  130.175  127.885  171.993\n",
            "5  xray  22.9647  24.2215   28.095  ...  140.018   102.64  109.368  172.793\n",
            "6   xrx  59.1384  58.6993   81.043  ...  71.2815  52.6067  51.2463  65.2734\n",
            "7   yum  16.9421  16.9405  21.6933  ...  197.551  139.148  154.555   247.26\n",
            "8   zbh  70.8296  68.4037  83.7801  ...  279.424  202.491  181.072  234.723\n",
            "9  zion  85.8273   84.841  120.583  ...  118.176  85.1557  85.8235  114.458\n",
            "\n",
            "[10 rows x 1096 columns]\n"
          ]
        }
      ],
      "source": [
        "print(\"Give me the input path\")\n",
        "filename_i = input()\n",
        "print(\"Give encoder name\")\n",
        "encoder = input()\n",
        "make_enc(filename_i,encoder)\n",
        "print(\"Give me the query path\")\n",
        "filename_q =input()\n",
        "\n",
        "make_enc(filename_q,encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlhYj8DHwfZF"
      },
      "outputs": [],
      "source": [
        "  #same for query\n",
        "def make_enc(filename,encoder):\n",
        "    df_q =pd.read_csv(filename ,delimiter='\\t', header=None)\n",
        "    df_q = df_q.T\n",
        "    print(f'Number of rows and columns: {df_q.shape}')\n",
        "    df_q.head(5)\n",
        "\n",
        "    to_be_encoded = []\n",
        "    s=0\n",
        "    #temp=temp.reshape(-1,1)\n",
        "    #successfully scaled after dayz xD\n",
        "    encoded_sc = []\n",
        "    encoded_set_scaled= []\n",
        "    to_be_encoded_final = []\n",
        "    training_set_scaled_cnn= []\n",
        "    for i in range (0,df_q.shape[1]):\n",
        "      encoded_set_scaled.append(MinMaxScaler(feature_range = (0, 1)))\n",
        "      temp=df_q[i][1:]\n",
        "      temp=np.array(temp)\n",
        "      temp=temp.reshape(-1,1)\n",
        "      temp = encoded_set_scaled[i].fit_transform(temp)\n",
        "      training_set_scaled_cnn.append(temp)  \n",
        "      s=0\n",
        "      while(s<len(df_q[0])-1):\n",
        "        tempo_x_train = temp[s:s+10]\n",
        "        \n",
        "        tempo_x_train=np.asarray(tempo_x_train).astype(np.float32)\n",
        "        to_be_encoded.append(tempo_x_train)\n",
        "        s=s+10\n",
        "      to_be_encoded_final.append(np.asarray(to_be_encoded).astype(np.float32))\n",
        "      to_be_encoded=[]\n",
        "    print((to_be_encoded_final[0][0]))\n",
        "\n",
        "    encoder = keras.models.load_model(encoder)\n",
        "    the_encoded = []\n",
        "    for i in range(0,df_q.shape[1]):\n",
        "      the_encoded.append(encoder.predict(to_be_encoded_final[i]))\n",
        "\n",
        "    print(len(the_encoded[0]))\n",
        "\n",
        "    new_list_q=[]\n",
        "    for i in range(0,df_q.shape[1]):\n",
        "      the_temp_encoded = the_encoded[i].reshape(-1,1)\n",
        "      the_temp_encoded = encoded_set_scaled[i].inverse_transform(the_temp_encoded)\n",
        "      k = the_temp_encoded.reshape(the_encoded[0].shape[0]*the_encoded[0].shape[1])\n",
        "      new_list_q.append(list(k))\n",
        "\n",
        "    new_df_q = pd.DataFrame()\n",
        "\n",
        "    for i in range(0,df_q.shape[1]):\n",
        "      new_list_q[i].insert(0,df_q[i][0])\n",
        "      new_df_q[i]=new_list_q[i]\n",
        "\n",
        "    new_df_q = new_df_q.T\n",
        "\n",
        "    print(new_df_q)\n",
        "    filname=filename[:-4]\n",
        "    filename= filename + \"enc.csv\"\n",
        "    k = new_df_q.to_csv(filname, sep='\\t', encoding='utf-8',header=False,index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "reduced.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
